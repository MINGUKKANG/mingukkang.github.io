<!DOCTYPE html> <html lang="en"> <head> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Minguk Kang</title> <meta name="author" content="Minguk Kang"/> <meta name="description" content="Minguk's personal webpage. Based on [*folio](https://github.com/bogoli/-folio) design. "/> <meta name="keywords" content="minguk"/> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"/> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/vs.css" media="none" id="highlight_theme_light"/> <link rel="shortcut icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>ðŸ”¥</text></svg>"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://mingukkang.github.io/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/zenburn.css" media="none" id="highlight_theme_dark"/> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <div class="navbar-brand social"> <a href="mailto:%6D%67%6B%61%6E%67@%70%6F%73%74%65%63%68.%61%63.%6B%72" title="email"><i class="fas fa-envelope"></i></a> <a href="https://scholar.google.com/citations?user=IwokTU4AAAAJ" title="Google Scholar" target="_blank" rel="noopener noreferrer"><i class="ai ai-google-scholar"></i></a> <a href="https://github.com/mingukkang" title="GitHub" target="_blank" rel="noopener noreferrer"><i class="fab fa-github"></i></a> <a href="https://www.linkedin.com/in/mingukkang" title="LinkedIn" target="_blank" rel="noopener noreferrer"><i class="fab fa-linkedin"></i></a> </div> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/">About<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">Blog</a> </li> <li class="nav-item"> <a class="nav-link" href="/assets/pdf/cv_minguk_Oct4.pdf" target="_blank" rel="noopener noreferrer">Curriculum Vitae</a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title"> <span class="font-weight-bold">Minguk</span> Kang </h1> <p class="desc"></p> </header> <article> <div class="profile float-right"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/prof_minguk-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/prof_minguk-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/prof_minguk-1400.webp"></source> <img src="/assets/img/prof_minguk.jpg" class="img-fluid z-depth-1 rounded-circle" width="auto" height="auto" alt="prof_minguk.jpg" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="address"> </div> </div> <div class="clearfix"> <p>I am a 5th year Ph.D. student in Graduate School of AI at <a href="https://postech.ac.kr/eng/" target="_blank" rel="noopener noreferrer">POSTECH</a>, where I am a member of the <a href="http://cvlab.postech.ac.kr/lab/" target="_blank" rel="noopener noreferrer">Computer Vision Lab</a> under the supervision of Prof. <a href="https://suhakwak.github.io" target="_blank" rel="noopener noreferrer">Suha Kwak</a> (2023â€“present). Previously, I was part of the same lab under the supervision of Prof. <a href="https://jaesik.info/" target="_blank" rel="noopener noreferrer">Jaesik Park</a> (2020â€“2023). From 2022 to 2024, I interned at Adobe Research, collaborating with wonderful colleagues: <a href="https://taesung.me/" target="_blank" rel="noopener noreferrer">Taesung Park</a>, <a href="https://www.cs.cmu.edu/~junyanz/" target="_blank" rel="noopener noreferrer">Jun-Yan Zhu</a>, <a href="https://richzhang.github.io/" target="_blank" rel="noopener noreferrer">Richard Zhang</a>, <a href="https://research.adobe.com/person/eli-shechtman/" target="_blank" rel="noopener noreferrer">Eli Shechtman</a>, <a href="https://research.adobe.com/person/sylvain-paris/" target="_blank" rel="noopener noreferrer">Sylvain Paris</a>, and <a href="https://www.connellybarnes.com/work/" target="_blank" rel="noopener noreferrer">Connelly Barnes</a>, where my research contributed to the development of Firefly. Previously, I received my B.S. in Engineering from Pusan National University.</p> <p>Starting in November 2024, I joined Pika as a Founding Research Scientist, expanding my experience in video generation.</p> <p>My research focuses on computer vision, particularly visual generative modeling and its applications. I am fascinated by the diverse range of vision-related tasks that Generative Adversarial Networks (GANs) can assist with. I am also interested in training large-scale diffusion models and exploring their applications. If you would like to know more about my research projects, please feel free to reach out to me.</p> <p>Email: mingukkang1994@gmail.com, mgkang@postech.ac.kr</p> </div> <div class="education"> <h2>Education</h2> <div class="table-responsive"> <table class="table table-sm table-borderless"> <tr> <th scope="row">Feb, 2020 - Present</th> <td> <a href="https://postech.ac.kr/eng/" target="_blank" rel="noopener noreferrer">Pohang University of Science and Technology (POSTECH)</a>, Pohang, South Korea <br> Integrated M.S./Ph.D. student in <a href="https://ai.postech.ac.kr/" target="_blank" rel="noopener noreferrer">Graduate School of AI</a> </td> </tr> <tr> <th scope="row">Mar, 2013 - Aug, 2019</th> <td> <a href="https://www.pusan.ac.kr/" target="_blank" rel="noopener noreferrer">Pusan National University</a>, Pusan, South Korea <br> B.S. in Engineering (Major: Mechanical Engineering and Minor: Statistics) </td> </tr> </table> </div> </div> <div class="experience"> <h2>Experience</h2> <div class="table-responsive"> <table class="table table-sm table-borderless"> <tr> <th scope="row">Nov, 2024 - Present</th> <td> <a href="https://pika.art/home" target="_blank" rel="noopener noreferrer">Pika labs</a>, Remote work at Korea <ul> <li>Founding Research Scientist</li> </ul> </td> </tr> <tr> <th scope="row">Jun, 2024 - Oct, 2024</th> <td> <a href="https://pika.art/home" target="_blank" rel="noopener noreferrer">Pika labs</a>, Palo Alto, United States of America <ul> <li>Research Scientist Intern</li> <li>Working with: <a href="https://cs.stanford.edu/~chenlin/" target="_blank" rel="noopener noreferrer">Chenlin Meng</a> </li> </ul> </td> </tr> <tr> <th scope="row">Jul, 2022 - May, 2024</th> <td> <a href="https://research.adobe.com/" target="_blank" rel="noopener noreferrer">Adobe Research Creative Intelligence Lab</a>, Remote work at Korea &amp; Onsite work at San Francisco <ul> <li>Research Scientist Intern</li> <li>Working with: <a href="https://taesung.me/" target="_blank" rel="noopener noreferrer">Taesung Park</a>, <a href="http://www.connellybarnes.com/work/" target="_blank" rel="noopener noreferrer">Connelly Barnes</a>, <a href="https://research.adobe.com/person/eli-shechtman/" target="_blank" rel="noopener noreferrer">Eli Shechtman</a>, <a href="https://www.cs.cmu.edu/~junyanz/" target="_blank" rel="noopener noreferrer">Jun-Yan Zhu</a>, <a href="http://richzhang.github.io" target="_blank" rel="noopener noreferrer">Richard Zhang</a>, <a href="https://research.adobe.com/person/sylvain-paris/" target="_blank" rel="noopener noreferrer">Sylvain Paris</a> </li> </ul> </td> </tr> <tr> <th scope="row">Feb, 2020 - Present</th> <td> <a href="http://cvlab.postech.ac.kr/lab/" target="_blank" rel="noopener noreferrer">Computer Vision Lab</a>, <a href="https://www.postech.ac.kr/eng/" target="_blank" rel="noopener noreferrer">POSTECH</a>, Pohang, South Korea <ul> <li>Integrated M.S./Ph.D. student</li> <li>Supervisors: Prof. <a href="https://suhakwak.github.io" target="_blank" rel="noopener noreferrer">Suha Kwak</a> (2023-present) and <a href="https://jaesik.info/" target="_blank" rel="noopener noreferrer">Jaesik Park</a> (2020-2023)</li> </ul> </td> </tr> <tr> <th scope="row">Aug, 2017 - Jan, 2020</th> <td> <a href="https://vislab.pusan.ac.kr/" target="_blank" rel="noopener noreferrer">Vision and Intelligent System Lab</a>, <a href="https://www.pusan.ac.kr/" target="_blank" rel="noopener noreferrer">Pusan National University</a>, Pusan, South Korea <ul> <li>Undergraduate Research Student</li> <li>Supervisor: Prof. <a href="https://vislab.pusan.ac.kr/visme/44915/subview.do" target="_blank" rel="noopener noreferrer">Dongjoong Kang</a> </li> </ul> </td> </tr> </table> </div> </div> <div class="news"> <h2>Softwares</h2> <div class="table-responsive"> <table class="table table-sm table-borderless"> <tr> <td> <ul> <li> <strong>Firefly</strong> is a text-to-image generative model developed by Adobe and integrated into Photoshop. My research contributed to the development of Firefly.</li> </ul> </td> </tr> <tr> <td> <ul> <li> <strong>StudioGAN</strong> is a Pytorch library providing implementations of representative Generative Adversarial Networks for image generation. I am the primary inventor of the StudioGAN library.</li> </ul> </td> </tr> </table> </div> </div> <div class="publications"> <h2>Publications</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-4"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/G_architecture-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/G_architecture-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/G_architecture-1400.webp"></source> <img src="/assets/img/G_architecture.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="kang2024diffusion2gan" class="col-sm-8"> <div class="title">Distilling Diffusion Models into Conditional GANs</div> <div class="author"> Minguk Kang,Â Richard Zhang,Â Connelly Barnes,Â Sylvain Paris,Â Suha Kwak,Â Jaesik Park,Â Eli Shechtman,Â Jun-Yan Zhu,Â  and Taesung Park </div> <div class="periodical"> <em>European Conference on Computer Vision (ECCV),</em> 2024 </div> <div class="links"> <a href="https://arxiv.org/abs/2405.05967" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Paper</a> <a href="https://github.com/mingukkang/elatentlpips" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a> <a href="https://mingukkang.github.io/Diffusion2GAN/" class="btn btn-sm z-depth-0" role="button">Website</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-4"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/23_arxiv3_seo-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/23_arxiv3_seo-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/23_arxiv3_seo-1400.webp"></source> <img src="/assets/img/publication_preview/23_arxiv3_seo.jpeg" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="seo2023risclip" class="col-sm-8"> <div class="title">Extending CLIPâ€™s Image-Text Alignment to Referring Image Segmentation</div> <div class="author"> Seoyeon Kim,Â Minguk Kang,Â Dongwon Kim,Â Jaesik Park,Â  and Suha Kwak </div> <div class="periodical"> <em>Annual Conference of the North American Chapter of the Association for Computational Linguistics (NAACL),</em> 2024 </div> <div class="links"> <a href="https://arxiv.org/abs/2306.08498" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Paper</a> <a href="https://github.com/Yeon07/RISCLIP" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-4"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/23_arxiv1_shin-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/23_arxiv1_shin-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/23_arxiv1_shin-1400.webp"></source> <img src="/assets/img/publication_preview/23_arxiv1_shin.jpeg" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="shin2023fillup" class="col-sm-8"> <div class="title">Fill-Up: Balancing Long-Tailed Data with Generative Models</div> <div class="author"> Joonghyuk Shin,Â Minguk Kang,Â  and Jaesik Park </div> <div class="periodical"> <em>arXiv preprint arXiv:2306.07200</em> 2023 </div> <div class="links"> <a href="https://arxiv.org/abs/2306.07200" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Paper</a> <a href="https://joonghyuk.com/Fill-Up/" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Website</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-4"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/22_studio_gan-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/22_studio_gan-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/22_studio_gan-1400.webp"></source> <img src="/assets/img/publication_preview/22_studio_gan.jpeg" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="kang2023StudioGANpami" class="col-sm-8"> <div class="title">StudioGAN: A Taxonomy and Benchmark of GANs for Image Synthesis</div> <div class="author"> Minguk Kang,Â Joonghyuk Shin,Â  and Jaesik Park </div> <div class="periodical"> <em>IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)</em> 2023 </div> <div class="links"> <a href="https://arxiv.org/abs/2206.09479" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Paper</a> <a href="https://github.com/POSTECH-CVLab/PyTorch-StudioGAN" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-4"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="https://raw.githubusercontent.com/stanford-crfm/helm/heim/src/helm/benchmark/static/heim/images/heim-logo-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="https://raw.githubusercontent.com/stanford-crfm/helm/heim/src/helm/benchmark/static/heim/images/heim-logo-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="https://raw.githubusercontent.com/stanford-crfm/helm/heim/src/helm/benchmark/static/heim/images/heim-logo-1400.webp"></source> <img src="https://raw.githubusercontent.com/stanford-crfm/helm/heim/src/helm/benchmark/static/heim/images/heim-logo.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="tony2023helm" class="col-sm-8"> <div class="title">Holistic Evaluation of Text-to-Image Models</div> <div class="author"> Tony Lee,Â Michihiro Yasunaga,Â Chenlin Meng,Â Yifan Mai,Â Joon Sung Park,Â Agrim Gupta,Â Yunzhi Zhang,Â Deepak Narayanan,Â Hannah Benita Teufel,Â Marco Bellagente,Â Minguk Kang,Â Taesung Park,Â Jure Leskovec,Â Jun-Yan Zhu,Â Li Fei-Fei,Â Jiajun Wu,Â Stefano Ermon,Â  and Percy Liang </div> <div class="periodical"> <em>Advances in Neural Information Processing Systems (NeurIPS), Datasets and Benchmarks Track, Spotlight</em> 2023 </div> <div class="links"> <a href="https://arxiv.org/abs/2311.04287" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Paper</a> <a href="https://github.com/stanford-crfm/helm" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Website</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-4"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/GigaGAN1-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/GigaGAN1-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/GigaGAN1-1400.webp"></source> <img src="/assets/img/publication_preview/GigaGAN1.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="kang2023gigagan" class="col-sm-8"> <div class="title">Scaling up GANs for Text-to-Image Synthesis</div> <div class="author"> Minguk Kang,Â Jun-Yan Zhu,Â Richard Zhang,Â Jaesik Park,Â Eli Shechtman,Â Sylvain Paris,Â  and Taesung Park </div> <div class="periodical"> <em>IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), Highlight,</em> 2023 </div> <div class="links"> <a href="https://arxiv.org/abs/2303.05511" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Paper</a> <a href="https://mingukkang.github.io/GigaGAN/" class="btn btn-sm z-depth-0" role="button">Website</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-4"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/22_context-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/22_context-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/22_context-1400.webp"></source> <img src="/assets/img/publication_preview/22_context.jpeg" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="cho2022context" class="col-sm-8"> <div class="title">Context-Aware Image Completion</div> <div class="author"> Jinoh Cho,Â Minguk Kang,Â Vibhav Vineet,Â  and Jaesik Park </div> <div class="periodical"> <em>IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshop,</em> 2023 </div> <div class="links"> <a href="https://arxiv.org/abs/2210.12350" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Paper</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-4"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/21_neurips1-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/21_neurips1-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/21_neurips1-1400.webp"></source> <img src="/assets/img/publication_preview/21_neurips1.jpeg" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="kang2021rebooting" class="col-sm-8"> <div class="title">Rebooting ACGAN: Auxiliary Classifier GANs with Stable Training</div> <div class="author"> Minguk Kang,Â Woohyeon Shim,Â Minsu Cho,Â  and Jaesik Park </div> <div class="periodical"> <em>Advances in Neural Information Processing Systems (NeurIPS),</em> 2021 </div> <div class="links"> <a href="https://arxiv.org/abs/2111.01118" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Paper</a> <a href="https://github.com/POSTECH-CVLab/PyTorch-StudioGAN" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-4"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/20_neurips-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/20_neurips-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/20_neurips-1400.webp"></source> <img src="/assets/img/publication_preview/20_neurips.jpeg" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="kang2020contragan" class="col-sm-8"> <div class="title">ContraGAN: Contrastive Learning for Conditional Image Generation</div> <div class="author"> Minguk Kang,Â  and Jaesik Park </div> <div class="periodical"> <em>Advances in Neural Information Processing Systems (NeurIPS),</em> 2020 </div> <div class="links"> <a href="https://arxiv.org/abs/2006.12681" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Paper</a> <a href="https://github.com/POSTECH-CVLab/PyTorch-StudioGAN" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a> </div> </div> </div> </li> </ol> </div> <div class="honors"> <h2>Honors and Awards</h2> <div class="table-responsive"> <table class="table table-sm table-borderless"> <tr> <td> <strong>Outstanding Reviewer, European Computer Vision Association (2024)</strong> <ul> <li>Nominated as one of the outstanding reviewers for ECCV.</li> </ul> <strong>Graduate School Presidential Science Scholarship (2024)</strong> <ul> <li>Received a scholarship totaling $26,000, which amounted to $1,450 per month over 18 months.</li> </ul> <strong>BK21 outstanding paper awards (2024)</strong> <ul> <li>2st prize ($375) - <em>Scaling up GANs for Text-to-Image Synthesis</em> (CVPR2023)</li> </ul> <strong>BK21 outstanding paper awards (2022)</strong> <ul> <li>1st prize ($750) - <em>Rebooting ACGAN: Auxiliary Classifier GANs with Stable Training</em> (NeurIPS2021)</li> </ul> <strong>Qualcomm Innovation Fellowship Korea (2021)</strong> <ul> <li>Winner ($3,000) - <em>ContraGAN: Contrastive Learning for Conditional Image Generation</em> (NeurIPS2020)</li> </ul> <strong>16th Samsung ElectroÂ­Mechanics Paper Awards (2020)</strong> <ul> <li>Silver prize ($2,500)</li> </ul> <strong>National Science and Engineering Scholarship (2013-2019)</strong> <ul> <li>Received full scholarship for 8 semesters ($15,000)</li> </ul> </td> </tr> </table> </div> </div> <div class="social"> <div class="contact-icons"> <a href="mailto:%6D%67%6B%61%6E%67@%70%6F%73%74%65%63%68.%61%63.%6B%72" title="email"><i class="fas fa-envelope"></i></a> <a href="https://scholar.google.com/citations?user=IwokTU4AAAAJ" title="Google Scholar" target="_blank" rel="noopener noreferrer"><i class="ai ai-google-scholar"></i></a> <a href="https://github.com/mingukkang" title="GitHub" target="_blank" rel="noopener noreferrer"><i class="fab fa-github"></i></a> <a href="https://www.linkedin.com/in/mingukkang" title="LinkedIn" target="_blank" rel="noopener noreferrer"><i class="fab fa-linkedin"></i></a> </div> <div class="contact-note"> </div> </div> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> Â© Copyright 2024 Minguk Kang. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" target="_blank" rel="noopener noreferrer">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="noopener noreferrer">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="/assets/js/common.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> </body> </html>